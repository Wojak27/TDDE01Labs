---
title: "Report_Lab2"
author: Karol Wojtulewicz
output: pdf_document
---
## Assignment 1
In this assignment we used the dataset "australian-crabs.csv".

### Assignment 1.1
Here we were supposed to plot the data from the dataset, RW against the CL and colour it by sex. The dataset looks to be suited for the discriminant analysis, becase it is mainly divided in two chunks of data with some overlapping points near the origin of the graph.

```{r assignment1.1, echo=FALSE}

data = read.csv(file="/Users/karolwojtulewicz/Google\ Drive/skola/TDDE01/Labs/Lab\ 2/australian-crabs.csv",head=TRUE,sep=",")
set.seed(12345)
# Assignment 1.1
plot(data$RW, data$CL, col= data$sex, xlab = "RW", ylab = "CL", main= "Original data distribution colored by sex")
```

### Assignment 1.2
In this subassignment we were supposed to (as in the previous assignment) plot the data from the plot and in addition use lda to classify the points, and use the prediction to colour them. Here we can see slight differences in how the LDA classified the points compairing to the original classes. As mentioned before, points near the origin of the graph cause some missclassififcation, but as we can see it is not significant as we can see in the print out underneeth the graph.
```{r assignment1.2, echo= FALSE}
# Assignment 1.2
#LDA - Linear Discriminant Analysis
data = read.csv(file="/Users/karolwojtulewicz/Google\ Drive/skola/TDDE01/Labs/Lab\ 2/australian-crabs.csv",head=TRUE,sep=",")
set.seed(12345)
library(MASS)
model.lda = lda(sex~RW+CL, data= data)
predictor.dataframe = data.frame(RW = data$RW, CL = data$CL)
colnames(predictor.dataframe) = c("RW", "CL")
predict.lda = predict(model.lda, predictor.dataframe)
plot(data$RW,data$CL, col= predict.lda$class, xlab = "RW", ylab = "CL")
misClasificError = mean(predict.lda$class != data$sex)
print(paste("Missclassification: ", misClasificError))
#Really good fit, misclassification error: 0.035. You can barelly see differences.
```

### Assignment 1.3
In this subassignment we were supposed to repeat the steps from the previous assignment, but with the prior of $p(Male)=0.9, p(Female)=0.1$. As wee can see below, some of the black dots form the previous graph turned red, indicating that the classified them as $Male$. Missclassification rate got higher from 0.035 to 0.08 which yields a worsen classifier.

```{r assignment1.3, echo=FALSE}
# Assignment 1.3
#LDA - Linear Discriminant Analysis
data = read.csv(file="/Users/karolwojtulewicz/Google\ Drive/skola/TDDE01/Labs/Lab\ 2/australian-crabs.csv",head=TRUE,sep=",")
set.seed(12345)
library(MASS)
model.lda = lda(sex~RW+CL, data= data, prior = c(0.1,0.9))
predictor.dataframe = data.frame(RW = data$RW, CL = data$CL)
colnames(predictor.dataframe) = c("RW", "CL")
predict.lda = predict(model.lda, predictor.dataframe)
plot(data$RW,data$CL, col= predict.lda$class, xlab = "RW", ylab = "CL")
misClasificError = mean(predict.lda$class != data$sex)
print(misClasificError)
#Really good fit, misclassification error: 0.08. You can barelly see differences.
```

### Assignment 1.4
Here we shall repeat the steps 1.2 and 1.3 but with logistic regression. The decision boundry in this case is $logit(t)=\ln(\frac{t}{1-t})$ where $t$ is our threshold (0.5 and 0.9). We can see in the graphs, that the story is not quite similar as it was with LDA, with slight differences (like the alone dot in the middle of the graph) and the same classification rate. We can see in the lower graph, how the points on the decision line turn black which is the result of our requirement $p(Male)=0.9,p(Female)=0.1$.

```{r assignment1.4, echo=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning = FALSE)
# Assignment 1.4a
#LDA - Linear Discriminant Analysis
data = read.csv(file="/Users/karolwojtulewicz/Google\ Drive/skola/TDDE01/Labs/Lab\ 2/australian-crabs.csv",head=TRUE,sep=",")
set.seed(12345)

model.log.reg = glm(sex~RW+CL,family=binomial(link='logit'), data= data)
predictor.dataframe = data.frame(RW = data$RW, CL = data$CL)
colnames(predictor.dataframe) = c("RW", "CL")
predict.log.reg = predict(model.log.reg, predictor.dataframe, type = "response" )
slope <- coef(model.log.reg)[2]/(-coef(model.log.reg)[3])
intercept <- coef(model.log.reg)[1]/(-coef(model.log.reg)[3])

predict.log.reg = ifelse(predict.log.reg > 0.5,"Male","Female") #Assignment 1.2
dataframe.sex = data.frame(sex = predict.log.reg)
plot(data$RW,data$CL, col= dataframe.sex$sex, xlab = "RW", ylab = "CL")
abline(intercept, slope, col = "blue")

misClasificError = mean(dataframe.sex$sex != data$sex)
print(misClasificError)
#Really good fit, misclassification error: 0.035. You can barelly see differences. 
#Same result as in 1.2

# Assignment 1.4b
#LDA - Linear Discriminant Analysis
data = read.csv(file="/Users/karolwojtulewicz/Google\ Drive/skola/TDDE01/Labs/Lab\ 2/australian-crabs.csv",head=TRUE,sep=",")
set.seed(12345)

model.log.reg = glm(sex~RW+CL,family=binomial(link='logit'), data= data)
slope <- coef(model.log.reg)[2]/(-coef(model.log.reg)[3])
intercept <- coef(model.log.reg)[1]/(-coef(model.log.reg)[3])
predictor.dataframe = data.frame(RW = data$RW, CL = data$CL)
colnames(predictor.dataframe) = c("RW", "CL")
predict.log.reg = predict(model.log.reg, predictor.dataframe, type = "response" )

predict.log.reg = ifelse(predict.log.reg > 0.9,"Male","Female") #Assignment 1.2
dataframe.sex = data.frame(sex = predict.log.reg)
plot(data$RW,data$CL, col= dataframe.sex$sex, xlab = "RW", ylab = "CL")
abline(intercept, slope, col = "blue")

misClasificError = mean(dataframe.sex$sex != data$sex)
print(misClasificError)
#Really good fit, misclassification error: 0.035. You can barelly see differences. 
#Same result as in 1.2

```

## Assignment 2
